88d7b12068b9 highmem: round down the address passed to kunmap_flush_on_unmap()
c0371782500c vringh: replace kmap_atomic() with kmap_local_page()
f7ef5fe74aaf mm/memory: replace kmap() with kmap_local_page()
489c693bd04a PM: hibernate: Use kmap_local_page() in copy_data_page()
73829b713470 zram: use kmap_local_page()
829c3151f0f8 mm/swapfile: replace kmap_atomic() with kmap_local_page()
003ae2fb0b36 mm/zswap: replace kmap_atomic() with kmap_local_page()
f542b8e582ab mm/page_poison: replace kmap_atomic() with kmap_local_page()
f2bcc99a5e90 mm/mempool: replace kmap_atomic() with kmap_local_page()
24d2613a6356 mm/memory: use kmap_local_page() in __wp_page_copy_user()
b33519896664 mm/ksm: use kmap_local_page() in calc_checksum()
2f7537620f38 mm/util: use kmap_local_page() in memcmp_pages()
ae96e0cdc78c lib: replace kmap() with kmap_local_page()
da1a055d01ed lib/test_bpf: Call page_address() on page acquired with GFP_KERNEL flag
3fda49e89f17 mm/swapfile: delete outdated pte_offset_map() comment
46c475bd676b mm/pgtable: kmap_local_page() instead of kmap_atomic()
0d508c1f0e2c userfaultfd: use kmap_local_page() in copy_huge_page_from_user()
1683ed16ff1a fs/nfs: Replace kmap_atomic() with kmap_local_page() in dir.c
0d78954a2d80 dm: prefer kmap_local_page() instead of deprecated kmap_atomic()
92b64bd01fe9 mm/highmem: add notes about conversions from kmap{,_atomic}()
e0820368d010 hostfs: Replace kmap() with kmap_local_page()
8eb29c4fbf96 dm flakey: fix a bug with 32-bit highmem systems
a3e2e248fd77 scsi: ipr: Replace kmap() with kmap_local_page()
7edd053b3327 scsi: ips: Replace kmap_atomic() with kmap_local_page()
d07bd950b91e crypto: skcipher - Use scatterwalk (un)map interface for dst and src buffers
f27c942e3e3e fs/cramfs: Convert kmap() to kmap_local_data()
aa9695157f65 crypto: scatterwalk - use kmap_local() not kmap_atomic()
a1db2f7edef0 fs/fuse: Replace kmap() with kmap_local_page()
5521de7dddd2 mm/userfaultfd: replace kmap/kmap_atomic() with kmap_local_page()
ef6e06b2ef87 highmem: fix kmap_to_page() for kmap_local_page() addresses
1d61261bfe8a swiotlb: replace kmap_atomic() with memcpy_{from,to}_page()
8377e8a24bba fs-verity: use kmap_local_page() instead of kmap()
c987918a3fdf fs-verity: use memcpy_from_page()
3a608cfee97e exec: Replace kmap{,_atomic}() with kmap_local_page()
a9e9c93966af Documentation/mm: add details about kmap_local_page() and preemption
72f1c55adf70 highmem: delete a sentence from kmap_local_page() kdocs
84b86f6054c4 Documentation/mm: rrefer kmap_local_page() and avoid kmap()
6b3afe2eeec2 Documentation/mm: avoid invalid use of addresses from kmap_local_page()
516ea046ec55 Documentation/mm: don't kmap*() pages which can't come from HIGHMEM
383bbef28392 highmem: specify that kmap_local_page() is callable from interrupts
729337bc2087 highmem: remove unneeded spaces in kmap_local_page() kdocs
1dd55358efc4 f2fs: Delete f2fs_copy_page() and replace with memcpy_page()
f2d57765b798 firmware_loader: Replace kmap() with kmap_local_page()
c6e8e36c6ae4 exec: Call kmap_local_page() in copy_string_kernel()
9384d79249d0 mm/highmem: delete memmove_page()
403d50341cce block: take destination bvec offsets into account in bio_copy_data_iter
110bf7a52307 Documentation/vm: rework "Temporary Virtual Mappings" section
85a85e760126 Documentation/vm: move "Using kmap-atomic" to highmem.h
e88a6a8fece9 binder: Use memcpy_{to,from}_page() in binder_alloc_do_buffer_copy()
1d625960e419 binder: Use kmap_local_page() in binder_alloc_copy_user_to_buffer()
26eff2d66aff binder: Use memset_page() in binder_alloc_clear_buf()
66f133ceab74 highmem: fix checks in __kmap_local_sched_{in,out}
d7ca25c53e25 highmem: document kunmap_local()
1cef171abd39 dm integrity: fix data corruption due to improper use of bvec_kmap_local
825c43f50e3a kmap_local: don't assume kmap PTEs are linear arrays in memory
d2c20e51e396 mm/highmem: remove deprecated kmap_atomic
30495e688d9d dm verity: use bvec_kmap_local in verity_for_bv_block
25058d1c725c dm integrity: use bvec_kmap_local in __journal_read_write
c12d205dae09 dm integrity: use bvec_kmap_local in integrity_metadata
5fe0fc9f1de6 fuse: use kmap_local_page()
513861202d12 highmem: don't disable preemption on RT in kmap_atomic()
ab069d5fdcd1 iomap: Use kmap_local_page instead of kmap_atomic
b405435b419c iomap: Support inline data with block size < page size
503469b5b30f block: use bvec_kmap_local in bio_integrity_process
8aec120a9ca8 block: use bvec_kmap_local in t10_pi_type1_{prepare,complete}
f8b679a070c5 block: rewrite bio_copy_data_iter to use bvec_kmap_local and memcpy_to_bvec
18a6234ccf06 dm-writecache: use bvec_kmap_local instead of bvec_kmap_irq
e6e7471706dc bvec: add a bvec_kmap_local helper
d9a42b53bdf7 mm: use kmap_local_page in memzero_page
8dad53a11f8d mm: call flush_dcache_page() in memcpy_to_page() and memzero_page()
2a510a744beb clean up copy_mc_pipe_to_iter()
893839fd5733 pipe_zero(): we don't need no stinkin' kmap_atomic()...
2495bdcc86dc iov_iter: clean csum_and_copy_...() primitives up a bit
55ca375c5dcc copy_page_from_iter(): don't need kmap_atomic() for kvec/bvec cases
c1d4d6a9ae88 copy_page_to_iter(): don't bother with kmap_atomic() for bvec/kvec cases
487cfade12fa mm/highmem: fix CONFIG_DEBUG_KMAP_LOCAL_FORCE_MAP
6a0996db6879 mm/highmem: Introduce memcpy_page(), memmove_page(), and memset_page()
61b205f57991 mm/highmem: Convert memcpy_[to|from]_page() to kmap_local_page()
a1dce7fd2ade mm/highmem: prepare for overriding set_pte_at()
29766bcffad0 net: support kmap_local forced debugging in skb_frag_foreach
f3ba3c710ac5 mm/highmem: Provide kmap_local*
5fbda3ecd14a sched: highmem: Store local kmaps in task struct
0e91a0c6984c mm/highmem: Provide CONFIG_DEBUG_KMAP_LOCAL_FORCE_MAP
6e799cb69a70 mm/highmem: Provide and use CONFIG_DEBUG_KMAP_LOCAL
2a656cad337e mm/highmem: Take kmap_high_get() properly into account
13f876ba77eb highmem: High implementation details and document API
3c1016b53c31 mm/highmem: Remove the old kmap_atomic cruft
d7029e454969 highmem: Get rid of kmap_types.h
e8f147dc3f1f fs: Remove asm/kmap_types.h includes
157e118b5511 x86/mm/highmem: Use generic kmap atomic implementation
389755c25081 highmem: Make DEBUG_HIGHMEM functional
298fa1ad5571 highmem: Provide generic variant of kmap_atomic*
b819fd9da385 highmem: Remove unused functions
4f8b96cd47b0 asm-generic: Provide kmap_size.h
106397376c0369 sbitmap: fix batching wakeup
b5fcf7871acb7f sbitmap: correct wake_batch recalculation to avoid potential IO hung
678418c6128f11 sbitmap: add sbitmap_find_bit to remove repeat code in __sbitmap_get/__sbitmap_get_shallow
08470a98a7d7e3 sbitmap: rewrite sbitmap_find_bit_in_index to reduce repeat code
903e86f3a64d95 sbitmap: remove redundant check in __sbitmap_queue_get_batch
f1591a8bb3e027 sbitmap: remove unnecessary calculation of alloc_hint in __sbitmap_get_shallow
26edb30dd1c0c9 sbitmap: Try each queue to wake up at least one waiter
976570b4ecd30d sbitmap: Advance the queue index before waking up a queue
4f8126bb230806 sbitmap: Use single per-bitmap counting to wake up queued tags
30514bd2dd4e86 sbitmap: fix lockup while swapping
4acb83417cadfd sbitmap: fix batched wait_cnt accounting
c35227d4e8cbc7 sbitmap: Use atomic_long_try_cmpxchg in __sbitmap_queue_get_batch
48c033314f3724 sbitmap: Avoid leaving waitqueue in invalid state in __sbq_wake_up()
ddbfc34fcf5d0b sbitmap: remove unnecessary code in __sbitmap_queue_get_batch
040b83fcecfb86 sbitmap: fix possible io hung due to lost wakeup
fbb564a5578094 lib/sbitmap: Fix invalid loop in __sbitmap_queue_get_batch()
863a66cdb4df25 lib/sbitmap: allocate sb->map via kvzalloc_node
3f607293b74d6a sbitmap: Delete old sbitmap_queue_get_shallow()
3301bc53358a0e lib/sbitmap: kill 'depth' from sbitmap_word
1fcbd5deac51f3 include/linux/sbitmap.h: replace kernel.h with the necessary inclusions
9f8b93a7df4d8e sbitmap: silence data race warning
1aec5e4a2962f7 sbitmap: add helper to clear a batch of tags
9672b0d4378204 sbitmap: add __sbitmap_queue_get_batch()
035e9f471691a1 scsi: sbitmap: Silence a debug kernel warning triggered by sbitmap_put()
2d13b1ea9f4aff scsi: sbitmap: Add sbitmap_calculate_shift() helper
cbb9950b41dd9d scsi: sbitmap: Export sbitmap_weight
c548e62bcf6adc scsi: sbitmap: Move allocation hint into sbitmap
bf2c4282a10a92 scsi: sbitmap: Add helpers for updating allocation hint
efe1f3a1d5833c scsi: sbitmap: Maintain allocation round_robin in sbitmap
4ec591790356f0 scsi: sbitmap: Remove sbitmap_clear_bit_unlock
0eff1f1a38a95b sbitmap: simplify wrap check
c3250c8d2451ff sbitmap: replace CAS with atomic and
661d4f55a79483 sbitmap: remove swap_lock
b78beea038a308 sbitmap: optimise sbitmap_deferred_clear()
e92072237e6c arm64: support huge vmalloc mappings
559089e0a93d vmalloc: replace VM_NO_HUGE_VMAP with VM_ALLOW_HUGE_VMAP
061478438d04 mm/page_alloc: further fix __alloc_pages_bulk() return value
e5c15cea3391 mm/page_alloc: correct return value when failing at preparing
66d9282523b3 mm/page_alloc: Correct return value of populated elements if bulk array is populated
e2c789cab60a dm: get rid of GFP_NOIO workarounds for __vmalloc and kvmalloc
30c19366636f mm: fix BUG splat with kvmalloc + GFP_ATOMIC
c572e4888ad1 mm/page_alloc: always attempt to allocate at least one page during bulk allocation
9becb6889130 kvmalloc: use vmalloc_huge for vmalloc allocations
8dcb3060d81d memcg: page_alloc: skip bulk allocator for __GFP_ACCOUNT
d8a719059b9d Revert "mm/pgtable: add stubs for {pmd/pub}_{set/clear}_huge"
b3b64ebd3822 mm/page_alloc: do bulk array bounds check after checking populated elements
b08e50dd6448 mm/page_alloc: __alloc_pages_bulk(): do bounds check before accessing array
86d0c1642725 mm/ioremap: fix iomap_max_page_shift
ca6c2ce1b481 mm/vmalloc: fix the unchecked dereference warning in vread_iter()
0d1c81edc61e mm/vmalloc: vmalloc_to_page() use pte_offset_kernel()
95a301eefa82 mm/vmalloc: do not output a spurious warning when huge vmalloc() fails
b3f78e749865 mm: vmalloc must set pte via arch code
77e50af07f14 mm/vmalloc: dont purge usable blocks unnecessarily
7f48121e9fa8 mm/vmalloc: add missing READ/WRITE_ONCE() annotations
43d7650234c6 mm/vmalloc: check free space in vmap_block lockless
a09fad96ffb1 mm/vmalloc: prevent flushing dirty space over and over
ca5e46c3400b mm/vmalloc: avoid iterating over per CPU vmap blocks twice
fc1e0d980037 mm/vmalloc: prevent stale TLBs in fully utilized blocks
fa1c77c13ca5 mm: vmalloc: rename addr_to_vb_xarray() function
062eacf57ad9 mm: vmalloc: remove a global vmap_blocks xarray
f349b15e183d mm: vmalloc: avoid warn_alloc noise caused by fatal signal
e9c3cda4d86e mm, vmalloc: fix high order __GFP_NOFAIL allocations
30a7a9b17c4b mm/vmalloc: skip the uninitilized vmalloc areas
bba9697b42ea mm/vmalloc: explicitly identify vm_map_ram area when shown in /proc/vmcoreinfo
06c8994626d1 mm/vmalloc.c: allow vread() to read out vm_map_ram areas
869176a09606 mm/vmalloc.c: add flags to mark vm_map_ram area
d76f99548cf0 mm/vmalloc.c: add used_map into vmap_block to track space of vmap_block
7e4a32c0e8ad mm/vmalloc: replace BUG_ON with a simple if statement
14687619e112 mm: vmalloc: replace BUG_ON() by WARN_ON_ONCE()
edd898181e2f mm: vmalloc: avoid calling __find_vmap_area() twice in __vunmap()
80b1d8fdfad1 mm: vmalloc: correct use of __GFP_NOWARN mask in __vmalloc_area_node()
bd1264c37c15 mm/vmalloc: extend find_vmap_lowest_match_check with extra arguments
08262ac50a7e mm/vmalloc.c: support HIGHMEM pages in vmap_pages_range_noflush()
899c6efe58db mm/vmalloc: extend __find_vmap_area() with one more argument
5d7a7c54d3d7 mm/vmalloc: initialize VA's list node after unlink
f9863be49312 mm/vmalloc: extend __alloc_vmap_area() with extra arguments
8eb510db2125 mm/vmalloc: make link_va()/unlink_va() common to different rb_root
baa468a648b4 mm/vmalloc: fix typo in local variable name
753df96be5d3 mm/vmalloc: remove the redundant boundary check
1b23ff80b399 mm/vmalloc: invoke classify_va_fit_type() in adjust_va_to_fit_type()
3f80492001aa mm/vmalloc: use raw_cpu_ptr() for vmap_block_queue access
4fcdcc12915c vmap(): don't allow invalid pages
3b8000ae185c mm/vmalloc: huge vmalloc backing pages should be split rather than compound
ff11a7ce1f0f mm/vmalloc: fix comments about vmap_area struct
c3385e845824 mm/vmalloc.c: fix "unused function" warning
c3d77172dfc0 mm/vmalloc: eliminate an extra orig_gfp_mask
9333fe98d0a6 mm/vmalloc: add adjust_search_size parameter
690467c81b1a mm/vmalloc: Move draining areas out of caller context
651d55ce0965 mm/vmalloc: remove unneeded function forward declaration
704687deaae7 mm: make slab and vmalloc allocators __GFP_NOLOCKDEP aware
a421ef303008 mm: allow !GFP_KERNEL allocations for kvmalloc
9376130c390a mm/vmalloc: add support for __GFP_NOFAIL
451769ebb7e7 mm/vmalloc: alloc GFP_NO{FS,IO} for vmalloc
084f7e2377e8 mm/large system hash: avoid possible NULL deref in alloc_large_system_hash
c00b6b961099 mm/vmalloc: introduce alloc_pages_bulk_array_mempolicy to accelerate memory allocation
3252b1d8309e kasan: arm64: fix pcpu_page_first_chunk crash with KASAN_VMALLOC
09cea6195073 arm64: support page mapping percpu first chunk allocator
0eb68437a7f9 vmalloc: choose a better start address in vm_area_register_early()
dd544141b9eb vmalloc: back off when the current task is OOM-killed
066fed59d8a1 mm/vmalloc: check various alignments when debugging
9f531973dff3 mm/vmalloc: do not adjust the search size for alignment overhead
ffb29b1c255a mm/vmalloc: fix numa spreading for large hash tables
f181234a5a21 mm/vmalloc: fix wrong behavior in vread
f8bcbecfb6b4 lib/test_vmalloc.c: add a new 'nr_pages' parameter
12e376a6f859 mm/vmalloc: remove gfpflags_allow_blocking() check
343ab8178f31 mm/vmalloc: use batched page requests in bulk-allocator
3382bbee0464 mm/vmalloc: enable mapping of huge pages at pte level in vmalloc
f7ee1f13d606 mm/vmalloc: enable mapping of huge pages at pte level in vmap
c742199a014d mm/pgtable: add stubs for {pmd/pub}_{set/clear}_huge
79c1c594f49a mm/hugetlb: change parameters of arch_make_huge_pte()
a850e932df65 mm: vmalloc: add cond_resched() in __vunmap()
12b9f873a5d0 mm/vmalloc: fallback to a single page allocator
f4bdfeaf18a4 mm/vmalloc: remove quoted strings split across lines
cd61413baa10 mm/vmalloc: print a warning message first on failure
5c1f4e690eec mm/vmalloc: switch to bulk allocator in __vmalloc_area_node()
a2afc59fb250 mm/page_alloc: add an alloc_pages_bulk_array_node() helper
15a64f5a8870 mm/vmalloc: add vmalloc_no_huge
3b822017b636 mm/page_alloc: inline __rmqueue_pcplist
ce76f9a1d9a2 mm/page_alloc: optimize code layout for __alloc_pages_bulk
0f87d9d30f21 mm/page_alloc: add an array-based interface to the bulk page allocator
387ba26fb1cb mm/page_alloc: add a bulk page allocator
f7c8ce44ebb1 mm/vmalloc: remove vwrite()
f2e762bab9f5 mm: remove xlate_dev_kmem_ptr()
bbcd53c96071 drivers/char: remove /dev/kmem for good
68d68ff6ebbf mm/mempool: minor coding style tweaks
299420ba358c mm/vmalloc: remove an empty line
187f8cc456f8 mm/vmalloc: refactor the preloading loagic
7bc4ca3ea956 vm/test_vmalloc.sh: adapt for updated driver interface
80f4759964cc lib/test_vmalloc.c: add a new 'nr_threads' parameter
a803315858bf lib/test_vmalloc.c: remove two kvfree_rcu() tests
d70bec8cc95a mm/vmalloc: improve allocation failure error messages
4ad0ae8c64ac mm/vmalloc: remove unmap_kernel_range
94f88d7b901c powerpc/xive: remove unnecessary unmap_kernel_range
e82b9b3086b9 kernel/dma: remove unnecessary unmap_kernel_range
b67177ecd956 mm/vmalloc: remove map_kernel_range
121e6f3258fe mm/vmalloc: hugepage vmalloc mappings
5d87510de15f mm/vmalloc: add vmap_range_noflush variant
5e9e3d777b99 mm: move vmap_range from mm/ioremap.c to mm/vmalloc.c
6f680e70b6ff mm/vmalloc: provide fallback arch huge vmap support functions
97dc2a1548ab x86: inline huge vmap supported functions
168a6333142b arm64: inline huge vmap supported functions
8309c9d71702 powerpc: inline huge vmap supported functions
bbc180a5adb0 mm: HUGE_VMAP arch support cleanup
95f0ddf081af mm/ioremap: rename ioremap_*_range to vmap_*_range
0a264884046f mm/vmalloc: rename vmap_*_range vmap_pages_*_range
0c95cba49255 mm: apply_to_pte_range warn and fail if a large pte is encountered
c0eb315ad971 mm/vmalloc: fix HUGE_VMAP regression by enabling huge pages in vmalloc_to_page
972472c7466b ARM: mm: add missing pud_page define to 2-level page tables
f608788cd2d6 mm/vmalloc: use rb_tree instead of list for vread() lookups
0f71d7e14c21 mm: unexport remap_vmalloc_range_partial
56db19fef3f1 docs/vm: remove unused 3 items explanation for /proc/vmstat
e924d461f2c3 mm/vmalloc.c: remove unnecessary return statement
799fa85d66e9 mm/vmalloc: add 'align' parameter explanation for pvm_determine_end_from_reverse
96e2db456135 mm/vmalloc: rework the drain logic
8945a723064a mm/vmalloc: use free_vm_area() if an allocation fails
34fe653716b0 mm/vmalloc.c:__vmalloc_area_node(): avoid 32-bit overflow
